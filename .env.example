# HiRAG configuration
# Copy this file to .env and fill in your values

# Provider selection - choose one: ollama, cohere, openai, deepseek, azure
PROVIDER=ollama

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OPENAI_MODEL_NAME=glm4  # This sets the LLM for Ollama
OLLAMA_EMBEDDING_MODEL=rjmalagon/gte-qwen2-7b-instruct:f16
OLLAMA_EMBEDDING_DIM=3584

# Cohere Configuration (required for run_cohere_pipeline.sh)
COHERE_API_KEY=your-cohere-api-key
COHERE_EMBEDDING_MODEL=embed-english-v3.0
COHERE_EMBEDDING_DIM=1024
COHERE_CHAT_MODEL=command
COHERE_MAX_TOKEN_SIZE=8192
COHERE_INPUT_TYPE=search_document

# OpenAI Configuration (optional)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL_NAME=gpt-4o-mini

# DeepSeek Configuration (optional)
# DEEPSEEK_API_KEY=your-deepseek-api-key
# DEEPSEEK_COMPLETION_MODEL=deepseek-chat

# Azure OpenAI Configuration (optional)
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_ENDPOINT=your-azure-endpoint
# AZURE_OPENAI_API_VERSION=2023-05-15

# Neo4j Configuration (optional)
# NEO4J_URI=neo4j://localhost:7687
# NEO4J_USER=neo4j
# NEO4J_PASSWORD=password

# Storage paths
WORKING_DIR=/path/to/your/working/directory 